{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vital-consumer",
   "metadata": {},
   "source": [
    "\n",
    "# Task: Word Recognition\n",
    "\n",
    "Goal of this project is to train a deep CNN model that can help in recognising a word, i.e. given a word-image(image with a word present in it) as input, the model yields a representation that can help in recognising the word from a set of possible words (termed as  'lexicon' of words). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-factory",
   "metadata": {},
   "source": [
    "# Method 1\n",
    "Using Alpha representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-ozone",
   "metadata": {},
   "source": [
    "# ALPHA REPRESENTATION\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-manufacturer",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-terrain",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-plain",
   "metadata": {},
   "source": [
    " **Alpha representation**: This is based on the claim that a word can be represented in terms of occurences of characters in various segments of image.\n",
    "\n",
    "The word is split into equal parts at various levels.\n",
    "\n",
    "At level *i*:  \n",
    "* A word is split into *i* (nearly) equal segments.  \n",
    "* For every segment, we compute a binary vector in which each segment correspond to alphabets/characters (Shown in fig.).\n",
    "\n",
    "![Alpha Vector](https://drive.google.com/uc?export=view&id=17rUvYXvWUc2IP8aD-O3kualSjr2dcn2b)\n",
    "\n",
    "*  Individual vectors of each segment are concatenated after one another, i.e. the level vector is obtained by concatenating individual vectors of first segment followed by second, third and so on.\n",
    "\n",
    "The final vector is obtained by concatenating vectors of all levels $\\{L_i.L_{i+1}.L_{i+2}\\cdots\\}$.\n",
    "\n",
    "\n",
    "*For this Project, i am using levels 2-5. \n",
    "This makes the length of final Alpha vector to be (2+3+4+5) * 26 = 364*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-advancement",
   "metadata": {},
   "source": [
    "**Note**: For both representations, while splitting, in case of unequal lengths of segments, segments at the end should be of more length e.g. Level 3 split of \"omega\" = {o,me,ga} and \"play\" = {p,l,ay}. Also, for a smaller words like \"ok\" level 3 split = {$\\epsilon$,o,k} where $\\epsilon$ = empty string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "obvious-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe the necessary libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "superb-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 50\n",
    "IMG_WIDTH = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-passion",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "The dataset used here is a synthetic word recognition dataset. It consists of images of lowercase English words, generated with handwritten-fonts. All images are single channel (grayscale) and have size 250 * 50. <br>\n",
    "\n",
    "The dataset has the following directory structure:\n",
    "\n",
    "<pre>\n",
    "<b>WR-Dataset</b>\n",
    "|__ <b>train</b>: [foo_1.png, bar_2.png, sample_3.png ....]\n",
    "|__ <b>validation</b>: [foo_221.png, bar_322.png, sample_353.png ....]\n",
    "|__ <b>test</b>: [bar_521.png, foo_272.png, example_433.png ....]\n",
    "|__ <b>Alphabet.csv</b>\n",
    "    \n",
    "</pre>\n",
    "\n",
    "Number of images in train,test and validate folder is 2052, 400 and 108 respectivly ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "above-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the paths for train, validation and test directories\n",
    "\n",
    "train_dir_path=\"C:/Users/hp/Desktop/PROJECT/Word_Recognition/WR-Dataset/Train\"\n",
    "validation_dir_path=\"C:/Users/hp/Desktop/PROJECT/Word_Recognition/WR-Dataset/Validation\"\n",
    "test_dir_path=\"C:/Users/hp/Desktop/PROJECT/Word_Recognition/WR-Dataset/Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-catalyst",
   "metadata": {},
   "source": [
    "# Visualizing sample images\n",
    "\n",
    "Prepare an image to label map and visualizing 5 randomly chosen images from training, validation and test sets (along with their labels). Also, Mention the number of word classes present in each of the three sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "graduate-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_count(df):\n",
    "    l = list(df['label'])\n",
    "    map = {}\n",
    "    for i in l:\n",
    "        map[i] = 0\n",
    "    return len(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accepting-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(img):\n",
    "    # Insert your code here to visualize a given image\n",
    "    %pylab inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.image as mpimg\n",
    "    img = mpimg.imread(img)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "educational-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(folder_name):\n",
    "    import glob\n",
    "    images_fullpath = glob.glob(folder_name + '/*')\n",
    "    images = []\n",
    "    for image in images_fullpath:\n",
    "        images.append(os.path.basename(image))\n",
    "    labels = []\n",
    "    for image in images:\n",
    "        labels.append(image.split(\"_\")[0])\n",
    "    data = np.column_stack((images,labels))\n",
    "    df = pandas.DataFrame(data = data, columns = ['Image','label']) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to build a dataframe with Images and their corresponding labels for 3 folders.\n",
    "test_df = get_dataframe(test_dir_path)\n",
    "train_df = get_dataframe(train_dir_path)\n",
    "validation_df = get_dataframe(validation_dir_path)\n",
    "\n",
    "# display the dataframes\n",
    "display(test_df)\n",
    "display(train_df)\n",
    "display(validation_df)\n",
    "\n",
    "# Visualise images from the train set\n",
    "print(\"Number of classes in Train set : \", get_classes_count(train_df))\n",
    "print(\"Images from Train Dataset\")\n",
    "for i in range(5):\n",
    "    visualize_image(train_dir_path + '/'+ random.choice(train_df['Image']))\n",
    "# Visualise images from the validation set\n",
    "print(\"Number of classes in Validation set : \", get_classes_count(validation_df))\n",
    "print(\"Images from Validation Dataset\")\n",
    "for i in range(5):\n",
    "    visualize_image(validation_dir_path + '/'+ random.choice(validation_df['Image']))\n",
    "\n",
    "# Visualise images from the test set\n",
    "print(\"Number of classes in Test set : \", get_classes_count(test_df))\n",
    "print(\"Images from Test Dataset\")\n",
    "for i in range(5):\n",
    "    visualize_image(test_dir_path + '/'+ random.choice(test_df['Image']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-pattern",
   "metadata": {},
   "source": [
    "# modules that can give  vector representations for the input words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aboriginal-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Vector(levels,word):\n",
    "    l = []\n",
    "    left = len(word)\n",
    "    pos = 0\n",
    "    while left:\n",
    "        temp = left // levels\n",
    "        l.append(word[pos:pos+temp])\n",
    "        pos += temp\n",
    "        left -= temp\n",
    "        levels -= 1\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "large-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Alpha_vector(word):\n",
    "  #Insert the code for a function that returns Alpha representation of the input word \n",
    "    l = []\n",
    "    for i in range(2,6):\n",
    "        temp = get_Vector(i,word)\n",
    "        l2 = []\n",
    "        for str in temp:\n",
    "            l3 = [0 for i in range(26)]\n",
    "            for c in str:\n",
    "                l3[ord(c)-ord('a')] = 1\n",
    "            l2.extend(l3)\n",
    "        l.extend(l2)\n",
    "    return l  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-volunteer",
   "metadata": {},
   "source": [
    "Let's test our Alpha Vector Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "assisted-modern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphavector: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "name = \"akash\"\n",
    "print(\"Alphavector:\",get_Alpha_vector(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-connectivity",
   "metadata": {},
   "source": [
    "# Building Alpha model architecture \n",
    "\n",
    "Following is the architecture of the model that will learn Alpha representation:\n",
    "\n",
    "Input shape: 250 * 50 ( RGB )\n",
    "\n",
    "\n",
    "* 2 Convolution layers with 64  filters\n",
    "* A Max Pool layer with pool size 2 * 2   \n",
    "* 2 Convolution layers with 128  filters\n",
    "* A Max Pool layer with pool size 2 * 2    \n",
    "* 6 Convolution layers with 256  filters\n",
    "* 3 Convolution layers with 512  filters\n",
    "* GLobal Average Pooling layer\n",
    "* Dense  layer with 4096 units\n",
    "* Dropout layer with rate 0.5\n",
    "* Dense  layer with 4096 units\n",
    "* Dropout layer with rate 0.5\n",
    "* Dense  layer with 364 units (Output)\n",
    "\n",
    "For all convolution layers,i kept kernel size as 3 * 3, use ReLu activation \n",
    "\n",
    "For all max pool layers, kept stride as 2\n",
    "\n",
    "For all dense layers, except the final layer used ReLu activation.\n",
    "\n",
    "For final layer, used sigmoid activation.\n",
    "\n",
    "**Loss function**: Binary cross-entropy\n",
    "\n",
    "**Similarity Metric**: Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alpha_model(learning_rate=1e-4):\n",
    "    # Instantiate Sequential model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    s = 2\n",
    "    # Add Layers\n",
    "    model.add(tf.keras.layers.Conv2D(strides = s,filters = 64, kernel_size = (3,3), activation='relu' ,input_shape=(IMG_HEIGHT,IMG_WIDTH, 3), padding = 'same'))\n",
    "    model.add(tf.keras.layers.Conv2D(strides = s,filters = 64, kernel_size = (3,3), activation='relu', padding = 'same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = 2))\n",
    "    model.add(tf.keras.layers.Conv2D(strides = s,filters = 128, kernel_size = (3,3), activation='relu', padding = 'same'))\n",
    "    model.add(tf.keras.layers.Conv2D(strides = s,filters = 128, kernel_size = (3,3), activation='relu', padding = 'same'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = 2))\n",
    "    for i in range(6):\n",
    "        model.add(tf.keras.layers.Conv2D(strides = s,filters = 256, kernel_size = (3,3), activation='relu', padding = 'same'))\n",
    "    for i in range(3):\n",
    "        model.add(tf.keras.layers.Conv2D(strides = s,filters = 512, kernel_size = (3,3), activation='relu', padding = 'same'))\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(364, activation='sigmoid'))\n",
    "\n",
    "    # Define optimizers(Adam Optimizers), loss function and similarity metrics\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()        \n",
    "    m = tf.keras.metrics.CosineSimilarity()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=opt, loss=loss, metrics=m)\n",
    "    \n",
    "    # return model\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-directory",
   "metadata": {},
   "source": [
    "we are using sigmoid as activation for final layer in Alpha model because output of the Alpha model is a binary vector so sigmoid is the best available activation function .\n",
    "we are using Binary Cross Entropy as loss function for final layer because  Binary Cross Entropy gives a binary output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-flush",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-place",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-compression",
   "metadata": {},
   "source": [
    "# Seen and Unseen Words\n",
    "----\n",
    "Words whose images hase been seen by the model during training are termed as seen words, while those which are part of the test set but not seen during training are called unseen words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to print seen word classes \n",
    "dict_seen = {}\n",
    "for label in train_df['label']:\n",
    "    dict_seen[label] = 1\n",
    "print(\"Seen words : \" , list(dict_seen.keys()))\n",
    "\n",
    "#Insert code to print unseen word classes from test set\n",
    "dict_unseen = {}\n",
    "for label in test_df['label']:\n",
    "    dict_unseen[label] = 1\n",
    "print(\"\\nUnseen words : \", list(dict_unseen.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "palestinian-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS=10\n",
    "BATCH_SIZE=8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-delight",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameters for Alpha Model\n",
    "We will now tune the *learning rate* for the Alpha model. \n",
    "\n",
    "For that, we first load the train and validation data (images and their labels, i.e. Alpha vectors) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fossil-toronto",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c492484f987a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dir_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIMG_HEIGHT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG_WIDTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "#code for loading train and validation set images and their corresponding labels \n",
    " \n",
    "x_train, y_train = [], []\n",
    "for i,row in train_df.iterrows():\n",
    "    image = tf.keras.preprocessing.image.load_img(train_dir_path + '/' + row['Image'], target_size = (IMG_HEIGHT, IMG_WIDTH))\n",
    "    x_train.append(tf.keras.preprocessing.image.img_to_array(image))\n",
    "    y_train.append(get_Alpha_vector(row['label']))\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "\n",
    "x_validate, y_validate = [], []\n",
    "for i,row in validation_df.iterrows():\n",
    "    image = tf.keras.preprocessing.image.load_img(validation_dir_path + '/' + row['Image'], target_size = (IMG_HEIGHT, IMG_WIDTH))\n",
    "    x_validate.append(tf.keras.preprocessing.image.img_to_array(image))\n",
    "    y_validate.append(get_Alpha_vector(row['label']))\n",
    "x_validate = np.asarray(x_validate) \n",
    "y_validate = np.asarray(y_validate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-knock",
   "metadata": {},
   "source": [
    "## Now find the best LR for the Alpha model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_Alpha_lr():\n",
    "    learning_rates = [1e-3,1e-4,1e-5]\n",
    "    avg_val_similarity = []\n",
    "    \n",
    "\n",
    "    for l_rate in learning_rates:\n",
    "        \n",
    "        # code to build a model with the current learning rate\n",
    "        model = Alpha_model(l_rate)\n",
    "        \n",
    "        # code to train the model using the training set and validate using the validation set\n",
    "        hist = model.fit(\n",
    "          x=x_train,y = y_train,epochs = NUM_EPOCHS ,batch_size = BATCH_SIZE,\n",
    "          validation_data=(x_validate, y_validate)).history\n",
    "        # code to find the average validation similarity for this model setting and append it to the maintained list\n",
    "        temp = np.mean(hist['val_cosine_similarity'])\n",
    "        avg_val_similarity.append(temp)\n",
    "\n",
    "    # code to figure out the learning rate which gives the highest average validation similarity. \n",
    "    pos = np.argmax(avg_val_similarity)\n",
    "    print(\"Learning Rate which gives highest validation accuracy : \", learning_rates[pos])\n",
    "    return learning_rates[pos]\n",
    "\n",
    "# determine_best_learning_rate() is being called here\n",
    "best_Alpha_lr = determine_Alpha_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-accordance",
   "metadata": {},
   "source": [
    "# Model building and training using callbacks\n",
    "---\n",
    "\n",
    "Now we will build and summarize the Alpha model as per the best learning rate value determined earlier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for building model using the best LR for Alpha model determined\n",
    "model_a = Alpha_model(best_Alpha_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-focus",
   "metadata": {},
   "source": [
    "Now instantiate the four callbacks for Alpha model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping after validation loss has not improved for 5 epochs \n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5)\n",
    "\n",
    "# ReduceLROnPlateau reducing LR by half when validation loss has not improved for 3 epochs. \n",
    "reduce_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# CSVlogger for keeping logs in filename of our choice\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('C:/Users/Ravi/Desktop/ML assignment 3/WR-Dataset/training2.csv')\n",
    "\n",
    "# ModelCheckpoint that saves the best weights of model after every 10 epochs\n",
    "checkpoint_filepath_alpha = 'C:/Users/Ravi/Desktop/ML assignment 3/WR-Dataset/checkpoints/cp1.ckpt'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath_alpha, save_best_only=True)\n",
    "\n",
    "callbacks = [earlystop_callback, reduce_callback, csv_logger, model_checkpoint_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-dimension",
   "metadata": {},
   "source": [
    "# Now we will train the model with training data using these callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to train with callbacks\n",
    "x_train, y_train = [], []\n",
    "for i,row in train_df.iterrows():\n",
    "    image = tf.keras.preprocessing.image.load_img(train_dir_path + '/' + row['Image'], target_size = (IMG_HEIGHT, IMG_WIDTH,3))\n",
    "    x_train.append(tf.keras.preprocessing.image.img_to_array(image))\n",
    "    y_train.append(get_Alpha_vector(row['label']))\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "\n",
    "# code for loading train and validation set images and their corresponding labels\n",
    "x_validate, y_validate = [], []\n",
    "for i,row in validation_df.iterrows():\n",
    "    image = tf.keras.preprocessing.image.load_img(validation_dir_path + '/' + row['Image'], target_size = (IMG_HEIGHT, IMG_WIDTH,3))\n",
    "    x_validate.append(tf.keras.preprocessing.image.img_to_array(image))\n",
    "    y_validate.append(get_Alpha_vector(row['label']))\n",
    "x_validate = np.asarray(x_validate) \n",
    "y_validate = np.asarray(y_validate)\n",
    "\n",
    "hist = model_a.fit(\n",
    "          x=x_train,y = y_train,epochs = 10,batch_size = BATCH_SIZE,\n",
    "          validation_data=(x_validate, y_validate), callbacks = callbacks).history\n",
    "\n",
    "# Insert your code here to obtain the lists: epochs, training similarity, validation similarity, training loss, validation loss from CSV log file (1 point)\n",
    "log_file = pandas.read_csv(\"C:/Users/Ravi/Desktop/ML assignment 3/WR-Dataset/training2.csv\")\n",
    "train_similarity = list(log_file['cosine_similarity'])\n",
    "valid_similarity = list(log_file['val_cosine_similarity'])\n",
    "train_loss = list(log_file['loss'])\n",
    "valid_loss = list(log_file['val_loss'])\n",
    "epochs = [i for i in range(1,11)]\n",
    "\n",
    "# Insert your code here to plot Epochs Vs. training and validation accuracy (2 points)\n",
    "fig, ax = plt.subplots(nrows=2, figsize = (20,20))\n",
    "data1 = list(zip(epochs,train_similarity, valid_similarity))\n",
    "data1 = pandas.DataFrame(data = data1, columns = ['epochs', 'Training Accuracy', 'Validation Accuracy'])\n",
    "data1 = pandas.melt(data1, id_vars = \"epochs\")\n",
    "sns.barplot(x=\"epochs\", y=\"value\", data=data1, ax = ax[0], hue = 'variable')\n",
    "\n",
    "# Insert your code here to plot Epochs Vs. training and validation loss (2 points)\n",
    "data2 = list(zip(epochs, train_loss, valid_loss))\n",
    "data2 = pandas.DataFrame(data = data2, columns = ['epochs', 'Training Loss', 'Validation Loss'])\n",
    "data2 = pandas.melt(data2, id_vars = \"epochs\")\n",
    "sns.barplot(x=\"epochs\", y=\"value\", data=data2, ax = ax[1], hue = 'variable')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-gabriel",
   "metadata": {},
   "source": [
    "## Steps for Word recognition:\n",
    "\n",
    "First, prepare a list having all the words from test set mapped to their corresponding vectors (lexicon for Alpha representations).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "word,a_vector = [], []  # y_test in label for Alpha model\n",
    "for i,row in test_df.iterrows():\n",
    "    word.append(row['label'])\n",
    "    a_vector.append(get_Alpha_vector(row['label']))\n",
    "alpha_map = zip(word, a_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-hotel",
   "metadata": {},
   "source": [
    "\n",
    "For every image in the test set we will be doing following step:\n",
    "1. Predict the output vector representation from the trained model(s) when the image is given as input.\n",
    "\n",
    "2. Find the word class(from lexicon) for which the similarity of its vector representation will be highest with the output vector.\n",
    "\n",
    "3. If predicted word = true word, then it is a correct prediction, otherwise incorrect prediction.\n",
    "\n",
    "---\n",
    "\n",
    "Let us now perform recognition using trained Alph amodel on the test set. \n",
    "\n",
    "First, load the test images and their vector representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to load test images and its vector labels (1 points)\n",
    "x_test, y_test = [], [] \n",
    "for i,row in test_df.iterrows():\n",
    "    image = tf.keras.preprocessing.image.load_img(test_dir_path + '/' + row['Image'], target_size = (IMG_HEIGHT, IMG_WIDTH))\n",
    "    x_test.append(tf.keras.preprocessing.image.img_to_array(image))\n",
    "    y_test.append(get_Alpha_vector(row['label']))\n",
    "x_test = np.asarray(x_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-columbia",
   "metadata": {},
   "source": [
    "\n",
    "Now we will load the saved trained Alpha model from the file and predict the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for loading the saved model from file \n",
    "alpha_saved_model = tf.keras.models.load_model(checkpoint_filepath_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "def get_label(result):\n",
    "    similarity = []\n",
    "    for label in a_vector:\n",
    "        similarity.append(1 - spatial.distance.cosine(label, result))\n",
    "    pos = np.argmax(similarity)\n",
    "    return word[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code for predicting word labels of the test set images \n",
    "output = alpha_saved_model.predict(x = x_test)\n",
    "output_labels = [get_label(res) for res in output]\n",
    "print(output_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-survey",
   "metadata": {},
   "source": [
    "\n",
    "Now Let us evaluate the performance of the model. The effective accuracy of model is defined as harmonic mean(HM) of accuracy with seen class images and accuracy with unseen class images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to compute accuracy of images that belong to seen classes \n",
    "acc2 = alpha_saved_model.evaluate(x_train, y_train)\n",
    "print(acc2[1])\n",
    "# Insert code to compute accuracy of images that belong to unseen classes\n",
    "acc1 = alpha_saved_model.evaluate(x_test,y_test)\n",
    "print(acc1[1])\n",
    "# Insert code to compute effective accuracy\n",
    "import statistics\n",
    "final_ac = statistics.harmonic_mean([acc2[1],acc1[1]])\n",
    "print(\"Harmonic accuracy : \",final_ac)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
